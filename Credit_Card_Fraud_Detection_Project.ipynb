{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2db805",
   "metadata": {},
   "source": [
    "# Projet : Mise en œuvre d'un modèle de Machine Learning avec TensorFlow\n",
    "\n",
    "Ce notebook couvre toutes les étapes nécessaires pour développer un modèle de détection de fraude par carte bancaire, depuis le traitement des données jusqu'à l'évaluation du modèle, conformément aux exigences du projet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c921f",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "\n",
    "Nous utilisons le dataset `Credit Card Fraud Detection` disponible sur Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08383748",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Chargement des données\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "print(data.head())\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c107580",
   "metadata": {},
   "source": [
    "## Préparation des données\n",
    "\n",
    "### Nettoyage des données et exploration initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c70331",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normalisation des données numériques\n",
    "scaler = StandardScaler()\n",
    "data['scaled_amount'] = scaler.fit_transform(data[['Amount']])\n",
    "data['scaled_time'] = scaler.fit_transform(data[['Time']])\n",
    "data = data.drop(['Time', 'Amount'], axis=1)\n",
    "\n",
    "# Exploration rapide des classes\n",
    "fraud = data[data['Class'] == 1]\n",
    "non_fraud = data[data['Class'] == 0]\n",
    "\n",
    "print(\"Nombre de transactions frauduleuses :\", len(fraud))\n",
    "print(\"Nombre de transactions non frauduleuses :\", len(non_fraud))\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(8, 5))\n",
    "data['Class'].value_counts().plot(kind='bar', title='Distribution des classes (fraude vs non-fraude)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f9c847",
   "metadata": {},
   "source": [
    "### Gestion du déséquilibre des classes avec SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1287c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Séparation des caractéristiques et étiquettes\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Application de SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"Distribution après SMOTE :\")\n",
    "print(y_resampled.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4ff53",
   "metadata": {},
   "source": [
    "## Mise en place de l'architecture du modèle\n",
    "\n",
    "Créons un réseau de neurones avec TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e120b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Création du modèle\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_resampled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ef707",
   "metadata": {},
   "source": [
    "## Entraînement du modèle\n",
    "\n",
    "Nous entraînons le modèle sur l'ensemble d'entraînement et utilisons la validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Séparation des ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29425d79",
   "metadata": {},
   "source": [
    "## Évaluation du modèle\n",
    "\n",
    "Calcul des métriques de performance et visualisation des résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Prédictions\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Matrice de Confusion\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
